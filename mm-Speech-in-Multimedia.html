<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Speech-in-Multimedia</title>
</head>
<body>
    <h2>Speech in Multimedia</h2>
    <p>Speech can be perceived, understood and generated by humans and also machines. A
        human adjust himself/herself very efficiently to different speakers and their speech habits.
        Different dialects and pronunciation, the speech can be well understood by humans. The brain
        can recognize the very fine line between speech and noise. The human speech signal comprise a
        subjective lowest spectral component known as the pitch, which is not proportional to frequency.
        Speech signals have two properties which can be used in speech processing:</p>
        <ul>
            <li>Voiced speech signals show during certain time intervals almost periodic behavior.
                Therefore, we can consider these signals as quasi-stationary signals for around 30
                milliseconds.</li>
            <li>The spectrum of audio signals shows characteristics maxima, which are mostly 3-5
                frequency bands. These maxima, called formants, occur because of resonances of the
                vocal tract.</li>
        </ul>
        <h3>Basic Notions related to speech</h3>
        <ul>
            <li>The lowest periodic spectral component of the speech signal is called the fundamental
                frequency. It is present in a voiced sound.</li>
            <li>A phone is the smallest speech unit, such as the m of mat and the b of bat in English, that
                distinguish one word from another in a given language.</li>
            <li>The Morph marks the smallest speech unit which carries a meaning itself. Therefore,
                consider is a morph, but reconsideration is not.</li>
            <li>A voiced sound is generated through the vocal cords. m,v and l are examples of voiced
                sounds. The pronunciation of a voiced sound depends strongly on each speaker.</li>
            <li>During the generation of an unvoiced sound, the vocal cords are opened. F and s are
                unvoiced sounds. Unvoiced sounds are relatively independent from the speaker.</li>
        </ul>
        <h3>Time-dependent sound concatenation</h3>
        <p>Speech generation/output can be performed by sound concatenation in a timely fashion.
            Individual speech units are composed like building blocks, where the composition can occur at
            different levels. In the simplest case, the individual phones are understood as speech units.
            Below figure shows the individual phones of the word crumb. It is possible with just a few
            phones to create an unlimited vocabulary.</p>
            <img src="phone sound concatenation.jpeg.png" alt="phone sound concatenation" width="500" height="100">
           <p>To make the transition problem easier, syllables can be created. The speech is generated through
            the set of syllables. Below figure shows the syllable sound of the word crumb. The best
            pronunciation of a word is achieved through storage of the whole word.</p>
            <img src="Syllable Sound.png" alt="Syllable Sound" width="500" height="100">
            
            <ul>
                <Li>The transition between individual sound unit create an essential problem, called
                    coarticulation, which is the mutual sound influence throughout several sounds.</Li>
                <Li>Prosody should be considered during speech generation/output. Prosody means the stress
                    and melody course. For example, pronunciation of a question differs from a statement.</Li>
                <Li>Prosody depends on the semantics of the speech and this has to be taken into
                    consideration during time-dependent sound concatenation.</Li>
            </ul>
            <h3>Frequency-dependent sound Concatenation</h3>
            <p>Speech generation/ output can also be based on a frequency-dependent sound
                concatenation, e.g. through a formant-synthesis. Formants are frequency maxima in the spectrum
                of the speech signal. Formant synthesis simulates the vocal tract through a filter. The
                characteristics values are the filterâ€™s middle frequencies and their bandwidths. A pulse signal
                with a frequency, corresponding to the fundamental speech frequency, is chosen as a simulation
                for voiced sounds. On the other hand unvoiced sounds are created through a noise generator.</p>
                <p>Individual speech elements (e.g. phones) are defiend through the characteristics values of
                    the formants. In frequency-dependent sound concatenation, the transition known as
                    coarticulation, present the most critical problem. Additionally, the respective prosody has to be
                    determined.</p>
    
</body>
</html>