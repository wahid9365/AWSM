<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>IMAGE ANALYSIS and IMAGE RECOGNITION</title>
</head>
<body>
    <h3>IMAGE ANALYSIS</h3>
    <p>Image analysis is concerned with techniques for extracting descriptions from images that
        are necessary for higher-level scene analysis methods. Image analysis techniques include
        computation of perceived brightness and color, partial or complete recovery of three-dimensional 
        data in the scene, location of discontinuities corresponding to objects in the scene and
        characterization of the properties of uniform regions in the image.</p>
        <p>Image analysis is important in many areas such as: aerial surveillance photographs, slow-
            scan television images of the moon or of planets gathered from space probes, television images
            taken from an industrial robot‟s visual sensor, X-ray images and computerized axial tomography
            (CAT) scans. Subareas of image processing include image enhancement, pattern detection and
            recognition and scene analysis and computer vision.</p>
            <p><b>Image enhancement </b>deals with improving image quality by eliminating noise (extraneous
                or missing pixels) or by enhancing contrast.</p>
                <p><b>Pattern detection and recognition</b> deal with detecting and clarifying standard patterns and
                    finding distortions from these patterns. A particularly important example is Optical Character
                    Recognition (OCR) technology, which allows for the economical bulk input of pages of typeset,
                    typewritten or even hand-printed characters.</p>
                    <p><b>Scene analysis and computer vision</b> deal with recognizing and reconstructing 3D models
                        of a scene from several 2D images. An example is an industrial robot sensing the relative sizes,
                        shapes, positions and colors of objects</p>

<h3>IMAGE RECOGNITION</h3>
                        <p>Image recognition, in the context of machine vision, is the ability of software to identify
                            objects, places, people, writing and actions in images. Computers can use machine vision
                            technologies in combination with a camera and artificial intelligence software to achieve image
                            recognition. To fully recognize an object in an image means knowing that there is an agreement
                            between the sensory projection and the observed image. How the object appears in the image has
                            to do with the spatial configuration of the pixel values. Agreement between the observed spatial
                            configuration and the expected sensory projection requires the following capabilities:</p>
    
<ul>
    <li>Infer explicitly or implicitly an object‟s position and orientation from the spatial
        configuration.</li>
        <li>Confirm that the inference is correct.</li>
</ul>
<p>To infer an object‟s (e.g., a cup) position, orientation and category or class from the
    spatial configuration of gray levels requires the capability to infer which pixels are parts of the
    object. Further, from among those pixels that are part of the object, it requires the capability to
    distinguish observed object features, such as special markings, lines, curves, surfaces or
    boundaries (e.g., edges of the cup). These features themselves are organized in a spatial
    relationship on the image and the object.</p>
    <p>Analytic inference of object shape, position and orientation depends on matching the
        distinguishing image features (in 2D, a point, line segment or region) with corresponding object
        features (in 3D, a point, line segment, arc segment, or a curved or planar surface).</p>
</body>
</html>